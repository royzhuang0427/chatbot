{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\莊帛軒\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\1. 精選單字20題\\Chris多益精選單字題.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\10. 多益分類單字本｜25主題篇章\\10 TOEIC VoCAb 多益衝刺單字分類整理 Chris.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\11 多益文法綜合模擬考50題\\50題 文法綜合模擬考題.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\2. 易混淆詞彙10題\\Chris易混淆詞.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\3. 各種代名詞20題\\各類代名詞考題.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\4. 精選詞性考題20題\\精選難的詞性考題20題.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\5. 時態語態考題大統整20題\\Chris 時態語態考題大統整.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\6. 介係詞考題25題\\Chris 介係詞考題.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\7. 分詞與動名詞混淆考法20題\\Chris易混淆詞分詞動名詞考法.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\8. 連接副詞10題\\Chris連接副詞統整.pdf\n",
      "正在讀取PDF：C:\\chatbot\\ENGLISHTEST\\result\\9. 假設語態考題10題\\Chris 假設語態考題.pdf\n",
      "文本已保存至 C:\\chatbot\\ENGLISHTEST\\result.txt\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "索引已保存到 c:\\chatbot\\ENGLISHTEST\\DB\\vector_index.faiss\n",
      "添加了新文本\n",
      "獲取文本時出錯: list index out of range\n",
      "獲取文本時出錯: list index out of range\n",
      "無效的輸入，請輸入 A、B、C、D 或 'skip'\n",
      "無效的輸入，請輸入 A、B、C、D 或 'skip'\n",
      "生成回應時出錯: name 'weight' is not defined\n",
      "\n",
      "GenAI 回覆: Here are five more TOEIC-style questions:\n",
      "\n",
      "**1. The company's financial reports show a significant increase in ------- sales over the past quarter.**\n",
      "(A) its (B) it's (C) their (D) they're\n",
      "\n",
      "**2. Before making a decision, the manager likes to consider ------- different perspectives on the issue.**\n",
      "(A) every (B) each (C) all (D) a few\n",
      "\n",
      "**3. The new employee was struggling to keep up with the workload, so her manager offered ------- assistance.**\n",
      "(A) her (B) she (C) hers (D) herself\n",
      "\n",
      "**4. The team has been working on the project for months, and ------- is finally nearing completion.**\n",
      "(A) it (B) that (C) this (D) which\n",
      "\n",
      "**5. In order to improve customer satisfaction, the company is planning to ------- its return policy.**\n",
      "(A) revise (B) review (C) renew (D) reform\n",
      "\n",
      "Let me know if you need help with answers and explanations!\n",
      "無效的輸入，請輸入 A、B、C、D 或 'skip'\n",
      "\n",
      "==================================================\n",
      "\n",
      "處理查詢時出錯: VectorDB.reembedding() missing 2 required positional arguments: 'folder_path' and 'output_txt_path'\n",
      "\n",
      "==================================================\n",
      "測驗結果:\n",
      "總分: 0.00%\n",
      "答題數: 0/1\n",
      "正確率: 0.00%\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "測驗結果:\n",
      "總分: 0.00%\n",
      "答題數: 0/1\n",
      "正確率: 0.00%\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "測驗結果:\n",
      "總分: 0.00%\n",
      "答題數: 0/1\n",
      "正確率: 0.00%\n",
      "==================================================\n",
      "\n",
      "處理查詢時出錯: VectorDB.reembedding() missing 2 required positional arguments: 'folder_path' and 'output_txt_path'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "from groq import Groq\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from DB.Datasource import VectorDB\n",
    "from Embedding.embedding import EmbeddingModel\n",
    "from utils.text_utils import save_source_in_txt\n",
    "from utils.scoring_utils import AnswerScoring\n",
    "\n",
    "scoring_system = AnswerScoring()\n",
    "\n",
    "load_dotenv(\"C:\\\\chatbot\\\\ENGLISHTEST\\\\.env\")\n",
    "if not os.getenv('GROQ_API_KEY'):\n",
    "    print(\"警告: GROQ_API_KEY 未設置\")\n",
    "groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "sys_msg = (\n",
    "    \"You are an experienced English teacher specializing in TOEIC preparation. \"\n",
    "    \"Your responsibilities include: \"\n",
    "    \"1. Creating TOEIC-style questions when requested \"\n",
    "    \"2. Providing detailed explanations for answers \"\n",
    "    \"3. Teaching relevant grammar points and vocabulary \"\n",
    "    \"4. Giving study tips and strategies \"\n",
    "    \"5. Correcting student's English mistakes \"\n",
    "    \"Please ensure all responses are in proper English. \"\n",
    "    \"When explaining, be thorough but easy to understand. \"\n",
    "    \"Always maintain a supportive and encouraging teaching tone.\"\n",
    ")\n",
    "\n",
    "convo = [{'role': 'system', 'content': sys_msg}]\n",
    "\n",
    "generation_config = {\n",
    "    'temperature': 0.95,\n",
    "    'top_p': 1,\n",
    "    'top_k': 5,\n",
    "    'max_output_tokens': 2048\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    {'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'},\n",
    "    {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'},\n",
    "    {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'},\n",
    "    {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'},\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest',\n",
    "                              generation_config=generation_config,\n",
    "                              safety_settings=safety_settings)\n",
    "MAX_CONVERSATION_LENGTH = 10\n",
    "\n",
    "def groq_prompt(prompt):\n",
    "    if len(convo) > MAX_CONVERSATION_LENGTH:\n",
    "        # 保留系統消息和最近的對話\n",
    "        convo[:] = [convo[0]] + convo[-MAX_CONVERSATION_LENGTH+1:]\n",
    "\n",
    "    convo.append({'role': 'user', 'content': prompt})\n",
    "    try:\n",
    "        chat_completion = groq_client.chat.completions.create(messages=convo, model='llama3-70b-8192')\n",
    "        response = chat_completion.choices[0].message\n",
    "        convo.append(response)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"調用Groq API時出錯: {e}\")\n",
    "        # 從對話歷史中移除失敗的提問\n",
    "        convo.pop()\n",
    "        return f\"系統出現錯誤：{str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "folder_path = \"C:\\\\chatbot\\\\ENGLISHTEST\\\\result\"\n",
    "output_txt_path = \"C:\\\\chatbot\\\\ENGLISHTEST\\\\result.txt\"\n",
    "\n",
    "\n",
    "def get_relevant_text_from_db(query, top_k=3):\n",
    "    try:\n",
    "        distances, indices = vector_db.search(query, top_k=top_k)\n",
    "        \n",
    "        # 確保 indices 非空且是有效格式\n",
    "        if not indices or isinstance(indices, (list, np.ndarray)) == False:\n",
    "            print(f\"警告: 返回的索引格式不正確或無相關文本，請檢查query: {query}\")\n",
    "            return \"\"\n",
    "\n",
    "        relevant_texts = []\n",
    "        if not isinstance(indices, (list, np.ndarray)):\n",
    "            indices = [indices]  # 確保 indices 是列表\n",
    "\n",
    "        for idx in indices:\n",
    "            if isinstance(idx, (list, np.ndarray)):\n",
    "                idx = idx[0]  # 如果 idx 是嵌套列表，取第一個元素\n",
    "            if isinstance(idx, int):  # 確保 idx 是整數\n",
    "                text = vector_db.get_text_by_index(idx)\n",
    "                if text and text != \"未找到相關文本\":\n",
    "                    relevant_texts.append(text)\n",
    "            else:\n",
    "                print(f\"警告: 無效的索引類型 {type(idx)}，跳過\")\n",
    "        \n",
    "        combined_text = \" \".join(relevant_texts)\n",
    "        return combined_text[:2000] if combined_text else \"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"獲取相關文本時出錯: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    \n",
    "def dynamic_weighting(response):\n",
    "    \n",
    "    score = len(response)\n",
    "    return score\n",
    "\n",
    "def generate_response_with_context(query):\n",
    "    try:\n",
    "        # 生成回應的過程\n",
    "        relevant_texts = get_relevant_text_from_db(query)\n",
    "        if not relevant_texts:\n",
    "            print(\"警告: 未找到相關文本，直接使用查詢生成回應\")\n",
    "            response = groq_prompt(query)\n",
    "        else:\n",
    "            prompt = (\n",
    "                f\"As an English teacher, please help with the following request while considering \"\n",
    "                f\"this reference material: {relevant_texts}\\n\\n\"\n",
    "                f\"Student's request: {query}\\n\\n\"\n",
    "                f\"Please provide a comprehensive response that includes:\\n\"\n",
    "                f\"1. Direct answer to the student's question\\n\"\n",
    "                f\"2. Relevant explanations or teaching points\\n\"\n",
    "                f\"3. Examples if applicable\\n\"\n",
    "                f\"4. Study tips or suggestions when appropriate\"\n",
    "            )\n",
    "            response = groq_prompt(prompt)\n",
    "\n",
    "        if \"A)\" in response and \"B)\" in response:  \n",
    "            question_id = len(scoring_system.correct_answers) + 1\n",
    "            correct_answer = \"A\"  \n",
    "            process_user_answer(question_id, correct_answer)\n",
    "\n",
    "            scoring_system.add_question(question_id, correct_answer, weight)  # 加入題目和答案\n",
    "            process_user_answer(question_id, correct_answer)  # 讓用戶回答並進行評分\n",
    "\n",
    "        score = dynamic_weighting(response)\n",
    "        print(f\"生成的答案: {response}\")\n",
    "        print(f\"答案得分: {score}\")\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"生成回應時出錯: {e}\")\n",
    "        return groq_prompt(query)\n",
    "    \n",
    "def save_response_to_txt(query, response, output_file=\"responses.txt\"):\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if not os.path.exists(output_file):\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# GenAI 回應記錄\\n\\n\")\n",
    "    with open(output_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"\\n{'='*50}\\n\")\n",
    "        f.write(f\"用戶提問: {query}\\n\") \n",
    "        f.write(f\"{'='*50}\\n\")\n",
    "        f.write(response)\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "def process_user_answer(question_id, correct_answer):\n",
    "    \"\"\"處理用戶答案輸入並累積評分\"\"\"\n",
    "    while True:\n",
    "        user_answer = input(f\"請輸入您的答案 (A/B/C/D) 問題 {question_id}，或輸入 'skip' 跳過: \").strip().upper()\n",
    "        if user_answer == 'SKIP':\n",
    "            return False\n",
    "        if user_answer in ['A', 'B', 'C', 'D']:\n",
    "            scoring_system.record_user_answer(question_id, user_answer)\n",
    "            if user_answer == correct_answer:\n",
    "                print(\"正確答案！\")\n",
    "            else:\n",
    "                print(f\"錯誤答案！正確答案是: {correct_answer}\")\n",
    "            return True\n",
    "        print(\"無效的輸入，請輸入 A、B、C、D 或 'skip'\")\n",
    "\n",
    "\n",
    "def show_results():\n",
    "    \"\"\"顯示測驗結果\"\"\"\n",
    "    total_score, percentage_score, wrong_questions = scoring_system.calculate_score()\n",
    "    stats = scoring_system.get_statistics()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"測驗結果:\")\n",
    "    print(f\"總分: {percentage_score:.2f}%\")\n",
    "    print(f\"答題數: {stats['answered_questions']}/{stats['total_questions']}\")\n",
    "    print(f\"正確率: {stats['accuracy']:.2f}%\")\n",
    "    \n",
    "    if wrong_questions:\n",
    "        print(\"\\n錯誤題目:\")\n",
    "        for wrong in wrong_questions:\n",
    "            print(f\"題號 {wrong['question_id']}:\")\n",
    "            print(f\"您的答案: {wrong['user_answer']}\")\n",
    "            print(f\"正確答案: {wrong['correct_answer']}\\n\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "try:\n",
    "    vector_db = VectorDB()\n",
    "    pdf_texts = vector_db.read_pdfs_in_folder(folder_path)\n",
    "    if pdf_texts:\n",
    "        save_source_in_txt(pdf_texts, output_txt_path) \n",
    "        for text in pdf_texts:\n",
    "            if vector_db.add_text(text):\n",
    "                print(\"添加了新文本\")\n",
    "            else:\n",
    "                print(\"文本已存在，跳過處理\")\n",
    "    else:\n",
    "        print(\"警告: 沒有找到PDF文件或文件讀取失敗\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"請輸入您的問題（輸入'quit'退出，'score'查看成績）: \")\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "            elif query.lower() == 'score':\n",
    "                show_results()\n",
    "                continue\n",
    "            elif query.lower() == 'reembedding':\n",
    "                vector_db.reembedding(folder_path)\n",
    "                continue\n",
    "            \n",
    "            response = generate_response_with_context(query)\n",
    "            save_response_to_txt(query, response)\n",
    "            print(\"\\nGenAI 回覆:\", response)\n",
    "            \n",
    "            if \"A)\" in response and \"B)\" in response: \n",
    "                question_id = len(scoring_system.correct_answers) + 1\n",
    "                \n",
    "                correct_answer = \"A\"  \n",
    "                weight = 1.0\n",
    "                \n",
    "                scoring_system.add_question(question_id, correct_answer, weight)\n",
    "                process_user_answer(question_id, correct_answer)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"處理查詢時出錯: {str(e)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"初始化過程出錯: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\莊帛軒\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化過程出錯: name '__file__' is not defined\n",
      "處理查詢時出錯: name 'vector_db' is not defined\n",
      "處理查詢時出錯: name 'vector_db' is not defined\n",
      "處理查詢時出錯: name 'vector_db' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vector_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 305\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m請輸入您的問題（輸入\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m退出）: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 320\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m處理查詢時出錯: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     \u001b[43mvector_db\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m程序結束，索引已保存\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_db' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pdfplumber\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from groq import Groq\n",
    "import google.generativeai as genai\n",
    "import openai\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"C:\\\\chatbot\\\\ENGLISHTEST\\\\.env\")\n",
    "if not os.getenv('GROQ_API_KEY'):\n",
    "    print(\"警告: GROQ_API_KEY 未設置\")\n",
    "groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "sys_msg = (\n",
    "    \"You are an experienced English teacher specializing in TOEIC preparation. \"\n",
    "    \"Your responsibilities include: \"\n",
    "    \"1. Creating TOEIC-style questions when requested \"\n",
    "    \"2. Providing detailed explanations for answers \"\n",
    "    \"3. Teaching relevant grammar points and vocabulary \"\n",
    "    \"4. Giving study tips and strategies \"\n",
    "    \"5. Correcting student's English mistakes \"\n",
    "    \"6. Providing detailed explanations for answers \"\n",
    "    \"7. Teaching relevant grammar points and vocabulary \"\n",
    "    \"8. Giving study tips and strategies \"\n",
    "    \"9. Correcting student's English mistakes \"\n",
    "    \"Please ensure all responses are in proper English. \"\n",
    "    \"When explaining, be thorough but easy to understand. \"\n",
    "    \"Always maintain a supportive and encouraging teaching tone.\"\n",
    ")\n",
    "\n",
    "convo = [{'role': 'system', 'content': sys_msg}]\n",
    "\n",
    "generation_config = {\n",
    "    'temperature': 0.95,\n",
    "    'top_p': 1,\n",
    "    'top_k': 5,\n",
    "    'max_output_tokens': 2048\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "    {'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'},\n",
    "    {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'},\n",
    "    {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'},\n",
    "    {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'},\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest',\n",
    "                              generation_config=generation_config,\n",
    "                              safety_settings=safety_settings)\n",
    "\n",
    "def groq_prompt(prompt):\n",
    "    convo.append({'role': 'user', 'content': prompt})\n",
    "    try:\n",
    "        chat_completion = groq_client.chat.completions.create(messages=convo, model='llama3-70b-8192')\n",
    "        response = chat_completion.choices[0].message\n",
    "        convo.append(response)\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Groq API: {e}\")\n",
    "        return \"系統出現錯誤\"\n",
    "\n",
    "\n",
    "\n",
    "folder_path = \"C:\\\\chatbot\\\\ENGLISHTEST\\\\result\"\n",
    "output_txt_path = \"C:\\\\chatbot\\\\ENGLISHTEST\\\\result.txt\"\n",
    "\n",
    "def read_pdf(pdf_path):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\" \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"讀取PDF時出錯 {pdf_path}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def read_pdfs_in_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"錯誤: 文件夾不存在 {folder_path}\")\n",
    "        return []\n",
    "    all_texts = []\n",
    "    \n",
    "    try:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    pdf_path = os.path.join(root, file)\n",
    "                    print(f\"正在讀取PDF：{pdf_path}\")\n",
    "                    text = read_pdf(pdf_path)\n",
    "                    if text:\n",
    "                        all_texts.append(text)\n",
    "    except Exception as e:\n",
    "        print(f\"讀取文件夾時出錯: {str(e)}\")\n",
    "    \n",
    "    return all_texts\n",
    "\n",
    "def save_sourse_in_txt(texts, output_txt_path):\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "        for i, text in enumerate(texts, 1):\n",
    "            f.write(f\"--- PDF {i} ---\\n\")\n",
    "            f.write(text)\n",
    "            f.write(\"\\n\\n\") \n",
    "    # print(f\"所有文字已儲存至 {output_txt_path}\")\n",
    "\n",
    "\n",
    "embed_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "def generate_embedding(text):\n",
    "    return embed_model.encode(text)\n",
    "\n",
    "def reembedding():\n",
    "    try:\n",
    "        print(\"開始重新embedding...\")\n",
    "        vector_db.clear_all()\n",
    "        \n",
    "        pdf_texts = read_pdfs_in_folder(folder_path)\n",
    "        if not pdf_texts:\n",
    "            print(\"警告: 沒有讀取到任何PDF文本\")\n",
    "            return\n",
    "        save_sourse_in_txt(pdf_texts, output_txt_path)\n",
    "        \n",
    "        for text in pdf_texts:\n",
    "            if vector_db.add_text(text):\n",
    "                print(\"添加了新文本\")\n",
    "        print(\"重新embedding完成\")\n",
    "    except Exception as e:\n",
    "        print(f\"重新embedding時出錯: {str(e)}\")\n",
    "\n",
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, dimension=384, index_file=\"vector_index.faiss\"):\n",
    "        self.dimension = dimension\n",
    "        self.index_file = os.path.join(os.path.dirname(__file__), index_file)\n",
    "        self.text_hash_file = os.path.join(os.path.dirname(__file__), \"text_hash_file.txt\")\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        self.texts = []\n",
    "        self.text_hashes = set() \n",
    "        self._load_index()\n",
    "        self._load_text_hashes()\n",
    "\n",
    "    def _load_text_hashes(self):\n",
    "        if os.path.exists(self.text_hash_file):\n",
    "            with open(self.text_hash_file, 'r') as f:\n",
    "                self.text_hashes = set(f.read().splitlines())\n",
    "\n",
    "    def _save_text_hashes(self):\n",
    "        with open(self.text_hash_file, 'w') as f:\n",
    "            f.write('\\n'.join(self.text_hashes))\n",
    "\n",
    "    def _load_index(self):\n",
    "        if os.path.exists(self.index_file):\n",
    "            try:\n",
    "                self.index = faiss.read_index(self.index_file) \n",
    "                # print(f\"Loaded existing index from {self.index_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading index: {e}\")\n",
    "        else:\n",
    "            print(f\"No existing index found. Creating a new one.\")\n",
    "            self.index = faiss.IndexFlatL2(self.dimension)\n",
    "            self.texts = [] \n",
    "\n",
    "    def _save_index(self):\n",
    "        faiss.write_index(self.index, self.index_file)\n",
    "        # print(f\"Index saved to {self.index_file}\")\n",
    "\n",
    "    def add_text(self, text, metadata=None):\n",
    "        text_hash = str(hash(text))\n",
    "        if text_hash in self.text_hashes:\n",
    "            return False\n",
    "        embedding = generate_embedding(text)\n",
    "        embedding = np.array(embedding, dtype=np.float32)\n",
    "        self.index.add(np.array([embedding], dtype=np.float32))\n",
    "        self.texts.append(text)\n",
    "        self.text_hashes.add(text_hash)\n",
    "        self._save_text_hashes()\n",
    "        self._save_index()\n",
    "        return True\n",
    "\n",
    "    def search(self, query, top_k=5):\n",
    "        query_embedding = generate_embedding(query)\n",
    "        distances, indices = self.index.search(np.array([query_embedding], dtype=np.float32), top_k)\n",
    "        return distances, indices\n",
    "    \n",
    "    def get_text_by_index(self, index):\n",
    "        try:\n",
    "            return self.texts[index]\n",
    "        except IndexError:\n",
    "            return \"未找到相關文本\"\n",
    "        \n",
    "    def _save_index(self):\n",
    "        try:\n",
    "            faiss.write_index(self.index, self.index_file)\n",
    "            print(f\"索引已保存到 {self.index_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存索引時出錯: {e}\")    \n",
    "        \n",
    "    def clear_all(self):\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        self.texts = []\n",
    "        self.text_hashes = set()\n",
    "        if os.path.exists(self.index_file):\n",
    "            os.remove(self.index_file)\n",
    "        if os.path.exists(self.text_hash_file):\n",
    "            os.remove(self.text_hash_file)\n",
    "        print(\"已清除所有向量数据\")\n",
    "\n",
    "    def close(self):\n",
    "        self._save_index()\n",
    "        self._save_text_hashes()\n",
    "\n",
    "\n",
    "\n",
    "def chunk_text(text, max_length=512):\n",
    "    sentences = text.split('.') \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        sentence_length = len(sentence.split())\n",
    "        if current_length + sentence_length <= max_length:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_length = sentence_length\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "def process_text_and_generate_embeddings(text):\n",
    "    chunks = chunk_text(text) \n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embedding = generate_embedding(chunk)\n",
    "        embeddings.append(embedding)\n",
    "        # print(f\"生成的嵌入: {embedding}\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "def get_relevant_text_from_db(query, top_k=3):\n",
    "    distances, indices = vector_db.search(query, top_k=top_k)\n",
    "    # 限制返回文本的長度\n",
    "    relevant_text = vector_db.get_text_by_index(0)\n",
    "    # 限制文本長度為 2000 字符\n",
    "    return relevant_text[:2000] if relevant_text else \"\"\n",
    "\n",
    "def generate_response_with_context(query):\n",
    "    relevant_texts = get_relevant_text_from_db(query)\n",
    "    prompt = (\n",
    "        f\"As an English teacher, please help with the following request while considering \"\n",
    "        f\"this reference material: {relevant_texts}\\n\\n\"\n",
    "        f\"Student's request: {query}\\n\\n\"\n",
    "        f\"Please provide a comprehensive response that includes:\\n\"\n",
    "        f\"1. Direct answer to the student's question\\n\"\n",
    "        f\"2. Relevant explanations or teaching points\\n\"\n",
    "        f\"3. Examples if applicable\\n\"\n",
    "        f\"4. Study tips or suggestions when appropriate\"\n",
    "    )\n",
    "    try:\n",
    "        response = groq_prompt(prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"API 錯誤: {e}\")\n",
    "        return groq_prompt(query)\n",
    "    \n",
    "def save_response_to_txt(query, response, output_file=\"responses.txt\"):\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if not os.path.exists(output_file):\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# GenAI 回應記錄\\n\\n\")\n",
    "    with open(output_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"\\n{'='*50}\\n\")\n",
    "        f.write(f\"用戶提問: {query}\\n\") \n",
    "        f.write(f\"{'='*50}\\n\")\n",
    "        f.write(response)\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "try:\n",
    "    vector_db = VectorDB()\n",
    "    pdf_texts = read_pdfs_in_folder(folder_path)\n",
    "    if pdf_texts:\n",
    "        save_sourse_in_txt(pdf_texts, output_txt_path)\n",
    "        for text in pdf_texts:\n",
    "            if vector_db.add_text(text):\n",
    "                print(\"添加了新文本\")\n",
    "            else:\n",
    "                print(\"文本已存在，跳過處理\")\n",
    "    else:\n",
    "        print(\"警告: 沒有找到PDF文件或文件讀取失敗\")\n",
    "except Exception as e:\n",
    "    print(f\"初始化過程出錯: {str(e)}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"請輸入您的問題（輸入'quit'退出）: \")\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "            elif query.lower() == 'reembedding':\n",
    "                reembedding()\n",
    "                continue\n",
    "            \n",
    "            response = generate_response_with_context(query)\n",
    "            save_response_to_txt(query, response)\n",
    "            print(\"\\nGenAI 回覆:\", response)\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"處理查詢時出錯: {str(e)}\")\n",
    "\n",
    "finally:\n",
    "    vector_db.close()\n",
    "    print(\"程序結束，索引已保存\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
